{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nE7b0ua-DNFs"
   },
   "source": [
    "# Proyecto "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLCwHb_tmabl"
   },
   "source": [
    "### 1. Perfilación y preparación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjzJz9gYmjXu"
   },
   "source": [
    "En las siguientes líneas de código se importan las librerías y herramientas necesarias para desarrollar el caso de uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8149,
     "status": "ok",
     "timestamp": 1648496801425,
     "user": {
      "displayName": "Carlos Figueredo Triana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJwxvb-2RbqLmvaMlAkGsK00dwDuMDh3eaDDbjvw=s64",
      "userId": "03942455958983780243"
     },
     "user_tz": 300
    },
    "id": "f5o1THt5C4j7",
    "outputId": "8ef757e9-cf7b-48da-fbec-126132fd5486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in c:\\users\\msi\\anaconda3\\lib\\site-packages (0.1.68)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from contractions) (0.0.21)\n",
      "Requirement already satisfied: anyascii in c:\\users\\msi\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.0)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\msi\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n"
     ]
    }
   ],
   "source": [
    "# Librería para manejar las contracciones que se presentan en el inglés.\n",
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47373,
     "status": "ok",
     "timestamp": 1648496848794,
     "user": {
      "displayName": "Carlos Figueredo Triana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJwxvb-2RbqLmvaMlAkGsK00dwDuMDh3eaDDbjvw=s64",
      "userId": "03942455958983780243"
     },
     "user_tz": 300
    },
    "id": "_Hoq934FC5pD",
    "outputId": "8e1edf03-d1a4-407c-9d64-21dc3ff8ded0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: inflect in c:\\users\\msi\\anaconda3\\lib\\site-packages (5.4.0)\n",
      "Requirement already satisfied: pandas-profiling==2.7.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: phik>=0.9.10 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from pandas-profiling==2.7.1) (0.12.2)\n",
      "Requirement already satisfied: htmlmin>=0.1.12 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from pandas-profiling==2.7.1) (0.1.12)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from pandas-profiling==2.7.1) (2.26.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from pandas-profiling==2.7.1) (1.20.3)\n",
      "Requirement already satisfied: matplotlib>=3.2.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from pandas-profiling==2.7.1) (3.4.3)\n",
      "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from pandas-profiling==2.7.1) (1.3.4)\n",
      "Requirement already satisfied: visions[type_image_path]==0.4.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from pandas-profiling==2.7.1) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.43.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from pandas-profiling==2.7.1) (4.62.3)\n",
      "Requirement already satisfied: astropy>=4.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from pandas-profiling==2.7.1) (4.3.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from pandas-profiling==2.7.1) (1.7.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\msi\\anaconda3\\lib\\site-packages (from pandas-profiling==2.7.1) (1.1.0)\n",
      "Requirement already satisfied: ipywidgets>=7.5.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from pandas-profiling==2.7.1) (7.6.5)\n",
      "Requirement already satisfied: missingno>=0.4.2 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from pandas-profiling==2.7.1) (0.5.1)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from pandas-profiling==2.7.1) (2.11.3)\n",
      "Requirement already satisfied: tangled-up-in-unicode>=0.0.4 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from pandas-profiling==2.7.1) (0.2.0)\n",
      "Requirement already satisfied: confuse>=1.0.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from pandas-profiling==2.7.1) (1.7.0)\n",
      "Requirement already satisfied: attrs>=19.3.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from visions[type_image_path]==0.4.1->pandas-profiling==2.7.1) (21.2.0)\n",
      "Requirement already satisfied: networkx>=2.4 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from visions[type_image_path]==0.4.1->pandas-profiling==2.7.1) (2.6.3)\n",
      "Requirement already satisfied: imagehash in c:\\users\\msi\\anaconda3\\lib\\site-packages (from visions[type_image_path]==0.4.1->pandas-profiling==2.7.1) (4.2.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\msi\\anaconda3\\lib\\site-packages (from visions[type_image_path]==0.4.1->pandas-profiling==2.7.1) (8.4.0)\n",
      "Requirement already satisfied: pyerfa>=1.7.3 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from astropy>=4.0->pandas-profiling==2.7.1) (2.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\msi\\anaconda3\\lib\\site-packages (from confuse>=1.0.0->pandas-profiling==2.7.1) (6.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from ipywidgets>=7.5.1->pandas-profiling==2.7.1) (7.29.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from ipywidgets>=7.5.1->pandas-profiling==2.7.1) (3.5.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from ipywidgets>=7.5.1->pandas-profiling==2.7.1) (1.0.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from ipywidgets>=7.5.1->pandas-profiling==2.7.1) (5.1.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from ipywidgets>=7.5.1->pandas-profiling==2.7.1) (5.1.3)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from ipywidgets>=7.5.1->pandas-profiling==2.7.1) (6.4.1)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (6.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (6.1.12)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (1.4.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.1.2)\n",
      "Requirement already satisfied: pygments in c:\\users\\msi\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (2.10.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (3.0.20)\n",
      "Requirement already satisfied: backcall in c:\\users\\msi\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (58.0.4)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.18.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\msi\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (5.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\msi\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.4.4)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\msi\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from jinja2>=2.11.1->pandas-profiling==2.7.1) (1.1.1)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (22.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (4.8.1)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (228)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling==2.7.1) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling==2.7.1) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling==2.7.1) (0.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\msi\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.2.0->pandas-profiling==2.7.1) (1.16.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\msi\\anaconda3\\lib\\site-packages (from missingno>=0.4.2->pandas-profiling==2.7.1) (0.11.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (3.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.18.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->pandas-profiling==2.7.1) (2021.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\msi\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.2.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from requests>=2.23.0->pandas-profiling==2.7.1) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from requests>=2.23.0->pandas-profiling==2.7.1) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from requests>=2.23.0->pandas-profiling==2.7.1) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from requests>=2.23.0->pandas-profiling==2.7.1) (2021.10.8)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (6.4.5)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.9.4)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\msi\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (20.1.0)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\msi\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (6.1.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\msi\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.11.0)\n",
      "Requirement already satisfied: pywinpty>=0.5 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.5.7)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (1.14.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\msi\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (2.20)\n",
      "Requirement already satisfied: PyWavelets in c:\\users\\msi\\anaconda3\\lib\\site-packages (from imagehash->visions[type_image_path]==0.4.1->pandas-profiling==2.7.1) (1.1.1)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\msi\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.7.1)\n",
      "Requirement already satisfied: testpath in c:\\users\\msi\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.5.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.8.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.3)\n",
      "Requirement already satisfied: bleach in c:\\users\\msi\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (4.0.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (1.4.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.5.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\msi\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.1.2)\n",
      "Requirement already satisfied: async-generator in c:\\users\\msi\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\msi\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (1.5.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\msi\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\msi\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (21.0)\n"
     ]
    }
   ],
   "source": [
    "# librería para manejar las flexiones gramaticales en el idioma inglés.\n",
    "!pip install inflect\n",
    "!pip install pandas-profiling==2.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1875,
     "status": "ok",
     "timestamp": 1648496850665,
     "user": {
      "displayName": "Carlos Figueredo Triana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJwxvb-2RbqLmvaMlAkGsK00dwDuMDh3eaDDbjvw=s64",
      "userId": "03942455958983780243"
     },
     "user_tz": 300
    },
    "id": "4vth9NgoC-cz",
    "outputId": "6da05c47-d2f1-40e2-a21d-bfb10a86f1d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# librería Natural Language Toolkit, usada para trabajar con textos \n",
    "import nltk\n",
    "# Punkt permite separar un texto en frases.\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1648496850665,
     "user": {
      "displayName": "Carlos Figueredo Triana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJwxvb-2RbqLmvaMlAkGsK00dwDuMDh3eaDDbjvw=s64",
      "userId": "03942455958983780243"
     },
     "user_tz": 300
    },
    "id": "KTyiKo7CDByj",
    "outputId": "07064df5-c4cd-40f9-c3b3-d17d138b7695"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descarga todas las palabras vacias, es decir, aquellas que no aportan nada al significado del texto\n",
    "# ¿Cuales son esas palabras vacías?\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 539,
     "status": "ok",
     "timestamp": 1648496851201,
     "user": {
      "displayName": "Carlos Figueredo Triana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJwxvb-2RbqLmvaMlAkGsK00dwDuMDh3eaDDbjvw=s64",
      "userId": "03942455958983780243"
     },
     "user_tz": 300
    },
    "id": "it_5D78tDERb",
    "outputId": "18986999-f73a-4ab7-8dfd-23683a8ff78f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\MSI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descarga de paquete WordNetLemmatizer, este es usado para encontrar el lema de cada palabra\n",
    "# ¿Qué es el lema de una palabra? ¿Qué tan dificil puede ser obtenerlo, piensa en el caso en que tuvieras que escribir la función que realiza esta tarea?\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 992,
     "status": "ok",
     "timestamp": 1648496852191,
     "user": {
      "displayName": "Carlos Figueredo Triana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJwxvb-2RbqLmvaMlAkGsK00dwDuMDh3eaDDbjvw=s64",
      "userId": "03942455958983780243"
     },
     "user_tz": 300
    },
    "id": "STtQz0GtDMOE"
   },
   "outputs": [],
   "source": [
    "# Instalación de librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import seaborn as sns\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "import re, string, unicodedata\n",
    "import contractions\n",
    "import inflect\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "from pandas.core.dtypes.generic import ABCIndex\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_precision_recall_curve\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from statistics import mode\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import validation_curve\n",
    "# Para búsqueda de hiperparámetros\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Para la validación cruzada\n",
    "from sklearn.model_selection import KFold \n",
    "# Para usar KNN como clasificador\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AY5bAgvrmrCh"
   },
   "source": [
    "Carga de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8396,
     "status": "ok",
     "timestamp": 1648496860584,
     "user": {
      "displayName": "Carlos Figueredo Triana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJwxvb-2RbqLmvaMlAkGsK00dwDuMDh3eaDDbjvw=s64",
      "userId": "03942455958983780243"
     },
     "user_tz": 300
    },
    "id": "LJmvYW5FQx3Q",
    "outputId": "7910439d-d705-4087-9d51-868b5edc310d"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 661,
     "status": "ok",
     "timestamp": 1648496861240,
     "user": {
      "displayName": "Carlos Figueredo Triana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJwxvb-2RbqLmvaMlAkGsK00dwDuMDh3eaDDbjvw=s64",
      "userId": "03942455958983780243"
     },
     "user_tz": 300
    },
    "id": "7mJaqBuImm6P"
   },
   "outputs": [],
   "source": [
    "# Se cargan los datos. \n",
    "#data=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Proyecto/clinical_trials_on_cancer_data_clasificacion.csv', sep=',', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cargan los datos. \n",
    "data=pd.read_csv('clinical_trials_on_cancer_data_clasificacion.csv', sep=',', encoding = 'utf-8', index_col=None, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1648496861241,
     "user": {
      "displayName": "Carlos Figueredo Triana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJwxvb-2RbqLmvaMlAkGsK00dwDuMDh3eaDDbjvw=s64",
      "userId": "03942455958983780243"
     },
     "user_tz": 300
    },
    "id": "-y5iPS89qED6",
    "outputId": "db2b88f4-0369-4614-d402-2898ad7937e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de datos y número de variables\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 674,
     "status": "ok",
     "timestamp": 1648496861910,
     "user": {
      "displayName": "Carlos Figueredo Triana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJwxvb-2RbqLmvaMlAkGsK00dwDuMDh3eaDDbjvw=s64",
      "userId": "03942455958983780243"
     },
     "user_tz": 300
    },
    "id": "7he4a7Z-qFjq",
    "outputId": "938e2596-7e6a-4683-c7d1-a5d9d4da9e9c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>study_and_condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>study interventions are Saracatinib . recurren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>study interventions are Stem cell transplantat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>study interventions are Lenograstim . recurren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>study interventions are Doxorubicin . stage ii...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>study interventions are Poly I-C . prostate ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                study_and_condition\n",
       "0  __label__0  study interventions are Saracatinib . recurren...\n",
       "1  __label__1  study interventions are Stem cell transplantat...\n",
       "2  __label__0  study interventions are Lenograstim . recurren...\n",
       "3  __label__0  study interventions are Doxorubicin . stage ii...\n",
       "4  __label__1  study interventions are Poly I-C . prostate ca..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar los datos\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1648496861911,
     "user": {
      "displayName": "Carlos Figueredo Triana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJwxvb-2RbqLmvaMlAkGsK00dwDuMDh3eaDDbjvw=s64",
      "userId": "03942455958983780243"
     },
     "user_tz": 300
    },
    "id": "6OtX5OS-qIFF"
   },
   "outputs": [],
   "source": [
    "# Es recomendable que todos los pasos preparación se realicen sobre otro archivo.\n",
    "data_t = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1648496861911,
     "user": {
      "displayName": "Carlos Figueredo Triana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJwxvb-2RbqLmvaMlAkGsK00dwDuMDh3eaDDbjvw=s64",
      "userId": "03942455958983780243"
     },
     "user_tz": 300
    },
    "id": "Wq2XQbi1V9nv",
    "outputId": "5d96a1b3-3381-460c-effa-3507ef20f350"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12000 entries, 0 to 11999\n",
      "Data columns (total 2 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   label                12000 non-null  object\n",
      " 1   study_and_condition  12000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 187.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1648496861911,
     "user": {
      "displayName": "Carlos Figueredo Triana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJwxvb-2RbqLmvaMlAkGsK00dwDuMDh3eaDDbjvw=s64",
      "userId": "03942455958983780243"
     },
     "user_tz": 300
    },
    "id": "ove5_Cx_IpUQ",
    "outputId": "14aa8f60-d297-4354-839a-c81c70ae717b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__label__0    6000\n",
       "__label__1    6000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4kzdQQ1Bww7"
   },
   "source": [
    "### Limpieza de los datos\n",
    "Para dejar el archivo en texto plano, sobre todo cuando vienen de diferentes fuentes como HTML, Twitter, XML, entre otros. También para eliminar caracteres especiales y pasar todo a minúscula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1648496862183,
     "user": {
      "displayName": "Carlos Figueredo Triana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJwxvb-2RbqLmvaMlAkGsK00dwDuMDh3eaDDbjvw=s64",
      "userId": "03942455958983780243"
     },
     "user_tz": 300
    },
    "id": "-WqU1EoMD9R7"
   },
   "outputs": [],
   "source": [
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_words.append(word.lower())\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    stop = stopwords.words('english')\n",
    "    \n",
    "    for word in words:\n",
    "        if word not in (stop):\n",
    "            new_words.append(word)\n",
    "\n",
    "    return new_words\n",
    "\n",
    "def preprocessing(words):\n",
    "    words = to_lowercase(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_non_ascii(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 170,
     "status": "ok",
     "timestamp": 1648496862352,
     "user": {
      "displayName": "Carlos Figueredo Triana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJwxvb-2RbqLmvaMlAkGsK00dwDuMDh3eaDDbjvw=s64",
      "userId": "03942455958983780243"
     },
     "user_tz": 300
    },
    "id": "kkJGwR9v6D28",
    "outputId": "bf437d8a-b3ed-43e4-b37c-1b350b5c4601"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__label__1    5996\n",
       "__label__0    5992\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminación registros con ausencias\n",
    "data_t = data_t.dropna()\n",
    "# Eliminación de registros duplicados.\n",
    "data_t = data_t.drop_duplicates()\n",
    "data_t['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_zBstsC5XtK"
   },
   "source": [
    "### Tokenización\n",
    "La tokenización permite dividir frases u oraciones en palabras. Con el fin de desglozar las palabras correctamente para el posterior análisis. Pero primero, se realiza una corrección de las contracciones que pueden estar presentes en los textos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 528,
     "status": "ok",
     "timestamp": 1648496862876,
     "user": {
      "displayName": "Carlos Figueredo Triana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJwxvb-2RbqLmvaMlAkGsK00dwDuMDh3eaDDbjvw=s64",
      "userId": "03942455958983780243"
     },
     "user_tz": 300
    },
    "id": "IEtBfwjJ2rrU"
   },
   "outputs": [],
   "source": [
    "data_t['study_and_condition'] = data_t['study_and_condition'].apply(contractions.fix) #Aplica la corrección de las contracciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 22520,
     "status": "ok",
     "timestamp": 1648496885393,
     "user": {
      "displayName": "Carlos Figueredo Triana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJwxvb-2RbqLmvaMlAkGsK00dwDuMDh3eaDDbjvw=s64",
      "userId": "03942455958983780243"
     },
     "user_tz": 300
    },
    "id": "tB_ashbN5jfx",
    "outputId": "91ca5f83-19e0-407a-ab04-856231323899"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>study_and_condition</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>study interventions are Saracatinib . recurren...</td>\n",
       "      <td>[study, interventions, saracatinib, recurrent,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>study interventions are Stem cell transplantat...</td>\n",
       "      <td>[study, interventions, stem, cell, transplanta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>study interventions are Lenograstim . recurren...</td>\n",
       "      <td>[study, interventions, lenograstim, recurrent,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>study interventions are Doxorubicin . stage ii...</td>\n",
       "      <td>[study, interventions, doxorubicin, stage, iii...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>study interventions are Poly I-C . prostate ca...</td>\n",
       "      <td>[study, interventions, poly, ic, prostate, can...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                study_and_condition  \\\n",
       "0  __label__0  study interventions are Saracatinib . recurren...   \n",
       "1  __label__1  study interventions are Stem cell transplantat...   \n",
       "2  __label__0  study interventions are Lenograstim . recurren...   \n",
       "3  __label__0  study interventions are Doxorubicin . stage ii...   \n",
       "4  __label__1  study interventions are Poly I-C . prostate ca...   \n",
       "\n",
       "                                               words  \n",
       "0  [study, interventions, saracatinib, recurrent,...  \n",
       "1  [study, interventions, stem, cell, transplanta...  \n",
       "2  [study, interventions, lenograstim, recurrent,...  \n",
       "3  [study, interventions, doxorubicin, stage, iii...  \n",
       "4  [study, interventions, poly, ic, prostate, can...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t['words'] = data_t['study_and_condition'].apply(word_tokenize).apply(preprocessing) #Aplica la eliminación del ruido\n",
    "data_t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OB4A4FHOpVMk"
   },
   "source": [
    "Eliminar palabras repetidas en todos los registros (study, interventions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 21261,
     "status": "ok",
     "timestamp": 1648496906650,
     "user": {
      "displayName": "Carlos Figueredo Triana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJwxvb-2RbqLmvaMlAkGsK00dwDuMDh3eaDDbjvw=s64",
      "userId": "03942455958983780243"
     },
     "user_tz": 300
    },
    "id": "AYXbK1F7pb5u",
    "outputId": "2dc2b2f9-cc6f-4c98-a4ca-0d192cdf3197"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>study_and_condition</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>study interventions are Saracatinib . recurren...</td>\n",
       "      <td>[saracatinib, recurrent, verrucous, carcinoma,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>study interventions are Stem cell transplantat...</td>\n",
       "      <td>[stem, cell, transplantation, hodgkin, lymphom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>study interventions are Lenograstim . recurren...</td>\n",
       "      <td>[lenograstim, recurrent, adult, diffuse, mixed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>study interventions are Doxorubicin . stage ii...</td>\n",
       "      <td>[doxorubicin, stage, iii, diffuse, large, cell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>study interventions are Poly I-C . prostate ca...</td>\n",
       "      <td>[poly, ic, prostate, cancer, diagnosis, unreso...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                study_and_condition  \\\n",
       "0  __label__0  study interventions are Saracatinib . recurren...   \n",
       "1  __label__1  study interventions are Stem cell transplantat...   \n",
       "2  __label__0  study interventions are Lenograstim . recurren...   \n",
       "3  __label__0  study interventions are Doxorubicin . stage ii...   \n",
       "4  __label__1  study interventions are Poly I-C . prostate ca...   \n",
       "\n",
       "                                               words  \n",
       "0  [saracatinib, recurrent, verrucous, carcinoma,...  \n",
       "1  [stem, cell, transplantation, hodgkin, lymphom...  \n",
       "2  [lenograstim, recurrent, adult, diffuse, mixed...  \n",
       "3  [doxorubicin, stage, iii, diffuse, large, cell...  \n",
       "4  [poly, ic, prostate, cancer, diagnosis, unreso...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_words = []\n",
    "for word in data_t['words']:\n",
    "    new_words = word.remove('study')\n",
    "    new_words = word.remove('interventions')\n",
    "    data_t['words'] = data_t['words'].replace(new_words)\n",
    "data_t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XB1_BLpm6QfL"
   },
   "source": [
    "### Normalización\n",
    "En la normalización de los datos se realiza la eliminación de prefijos y sufijos, además de realizar una lemmatización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 7739,
     "status": "ok",
     "timestamp": 1648496914385,
     "user": {
      "displayName": "Carlos Figueredo Triana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJwxvb-2RbqLmvaMlAkGsK00dwDuMDh3eaDDbjvw=s64",
      "userId": "03942455958983780243"
     },
     "user_tz": 300
    },
    "id": "pCX5EHqq5yVF",
    "outputId": "ef190d5e-88d7-4427-ad19-6370f0f57954"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>study_and_condition</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>study interventions are Saracatinib . recurren...</td>\n",
       "      <td>[saracatinib, recurr, verruc, carcinoma, laryn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>study interventions are Stem cell transplantat...</td>\n",
       "      <td>[stem, cell, transplant, hodgkin, lymphoma, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>study interventions are Lenograstim . recurren...</td>\n",
       "      <td>[lenograstim, recurr, adult, diffus, mix, cell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>study interventions are Doxorubicin . stage ii...</td>\n",
       "      <td>[doxorubicin, stage, iii, diffus, larg, cell, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>study interventions are Poly I-C . prostate ca...</td>\n",
       "      <td>[poli, ic, prostat, cancer, diagnosi, unresolv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                study_and_condition  \\\n",
       "0  __label__0  study interventions are Saracatinib . recurren...   \n",
       "1  __label__1  study interventions are Stem cell transplantat...   \n",
       "2  __label__0  study interventions are Lenograstim . recurren...   \n",
       "3  __label__0  study interventions are Doxorubicin . stage ii...   \n",
       "4  __label__1  study interventions are Poly I-C . prostate ca...   \n",
       "\n",
       "                                               words  \n",
       "0  [saracatinib, recurr, verruc, carcinoma, laryn...  \n",
       "1  [stem, cell, transplant, hodgkin, lymphoma, di...  \n",
       "2  [lenograstim, recurr, adult, diffus, mix, cell...  \n",
       "3  [doxorubicin, stage, iii, diffus, larg, cell, ...  \n",
       "4  [poli, ic, prostat, cancer, diagnosi, unresolv...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    #https://www.datacamp.com/community/tutorials/stemming-lemmatization-python\n",
    "    porter = PorterStemmer()\n",
    "    lancaster=LancasterStemmer()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_words.append(porter.stem(word))\n",
    "    return new_words\n",
    "        \n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    #https://www.geeksforgeeks.org/python-lemmatization-approaches-with-examples/\n",
    "    wnl = WordNetLemmatizer()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_words.append(wnl.lemmatize(word))\n",
    "    return new_words\n",
    "\n",
    "\n",
    "def stem_and_lemmatize(words):\n",
    "    stems = stem_words(words)\n",
    "    lemmas = lemmatize_verbs(words)\n",
    "    return stems + lemmas\n",
    "\n",
    "\n",
    "data_t['words'] = data_t['words'].apply(stem_and_lemmatize) #Aplica lematización y Eliminación de Prefijos y Sufijos.\n",
    "data_t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pl9rCE9cB9fi"
   },
   "source": [
    "###  Selección de campos\n",
    "\n",
    "Primero, se separa la variable predictora y los textos que se van a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1648496914386,
     "user": {
      "displayName": "Carlos Figueredo Triana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJwxvb-2RbqLmvaMlAkGsK00dwDuMDh3eaDDbjvw=s64",
      "userId": "03942455958983780243"
     },
     "user_tz": 300
    },
    "id": "zJeWdp8G-Srl",
    "outputId": "a08107b3-3410-405c-d693-b9c6c46324e0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>study_and_condition</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>study interventions are Saracatinib . recurren...</td>\n",
       "      <td>saracatinib recurr verruc carcinoma larynx dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>study interventions are Stem cell transplantat...</td>\n",
       "      <td>stem cell transplant hodgkin lymphoma diagnosi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>study interventions are Lenograstim . recurren...</td>\n",
       "      <td>lenograstim recurr adult diffus mix cell lymph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>study interventions are Doxorubicin . stage ii...</td>\n",
       "      <td>doxorubicin stage iii diffus larg cell lymphom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>study interventions are Poly I-C . prostate ca...</td>\n",
       "      <td>poli ic prostat cancer diagnosi unresolv ira f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>study interventions are Prednisolone hemisucci...</td>\n",
       "      <td>prednisolon hemisuccin recurr childhood larg c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>study interventions are Bevacizumab . recurren...</td>\n",
       "      <td>bevacizumab recurr rectal cancer diagnosi abso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>__label__1</td>\n",
       "      <td>study interventions are Antibodies, Monoclonal...</td>\n",
       "      <td>antibodi monoclon recurr lymphoblast lymphoma ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>study interventions are Vorinostat . colorecta...</td>\n",
       "      <td>vorinostat colorect cancer diagnosi patient mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>__label__0</td>\n",
       "      <td>study interventions are Freund's Adjuvant . ov...</td>\n",
       "      <td>freund adjuv ovarian cancer diagnosi four week...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11988 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            label                                study_and_condition  \\\n",
       "0      __label__0  study interventions are Saracatinib . recurren...   \n",
       "1      __label__1  study interventions are Stem cell transplantat...   \n",
       "2      __label__0  study interventions are Lenograstim . recurren...   \n",
       "3      __label__0  study interventions are Doxorubicin . stage ii...   \n",
       "4      __label__1  study interventions are Poly I-C . prostate ca...   \n",
       "...           ...                                                ...   \n",
       "11995  __label__0  study interventions are Prednisolone hemisucci...   \n",
       "11996  __label__0  study interventions are Bevacizumab . recurren...   \n",
       "11997  __label__1  study interventions are Antibodies, Monoclonal...   \n",
       "11998  __label__0  study interventions are Vorinostat . colorecta...   \n",
       "11999  __label__0  study interventions are Freund's Adjuvant . ov...   \n",
       "\n",
       "                                                   words  \n",
       "0      saracatinib recurr verruc carcinoma larynx dia...  \n",
       "1      stem cell transplant hodgkin lymphoma diagnosi...  \n",
       "2      lenograstim recurr adult diffus mix cell lymph...  \n",
       "3      doxorubicin stage iii diffus larg cell lymphom...  \n",
       "4      poli ic prostat cancer diagnosi unresolv ira f...  \n",
       "...                                                  ...  \n",
       "11995  prednisolon hemisuccin recurr childhood larg c...  \n",
       "11996  bevacizumab recurr rectal cancer diagnosi abso...  \n",
       "11997  antibodi monoclon recurr lymphoblast lymphoma ...  \n",
       "11998  vorinostat colorect cancer diagnosi patient mu...  \n",
       "11999  freund adjuv ovarian cancer diagnosi four week...  \n",
       "\n",
       "[11988 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t['words'] = data_t['words'].apply(lambda x: ' '.join(map(str, x)))\n",
    "data_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1648496914387,
     "user": {
      "displayName": "Carlos Figueredo Triana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJwxvb-2RbqLmvaMlAkGsK00dwDuMDh3eaDDbjvw=s64",
      "userId": "03942455958983780243"
     },
     "user_tz": 300
    },
    "id": "F4HJTL3Ig9LU"
   },
   "outputs": [],
   "source": [
    "data_t['label'] = data_t['label'].replace(['__label__1'],1)\n",
    "data_t['label'] = data_t['label'].replace(['__label__0'],0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVtwchyD2DdS"
   },
   "source": [
    "Aplicamos TF_IDF (Term-frecuency times inverse Document-frecuency) a los datos\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "executionInfo": {
     "elapsed": 118975,
     "status": "ok",
     "timestamp": 1648497033626,
     "user": {
      "displayName": "Carlos Figueredo Triana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgJwxvb-2RbqLmvaMlAkGsK00dwDuMDh3eaDDbjvw=s64",
      "userId": "03942455958983780243"
     },
     "user_tz": 300
    },
    "id": "TkxDexScQ4W8",
    "outputId": "d5aeb01c-3077-443a-c714-7b4a0d6ceabe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>01</th>\n",
       "      <th>01910na</th>\n",
       "      <th>025</th>\n",
       "      <th>05</th>\n",
       "      <th>09</th>\n",
       "      <th>0three_two9</th>\n",
       "      <th>0two_two009</th>\n",
       "      <th>10deazaaminopterin</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>zivaflibercept</th>\n",
       "      <th>zk</th>\n",
       "      <th>zoladex</th>\n",
       "      <th>zoledron</th>\n",
       "      <th>zoledronate</th>\n",
       "      <th>zoledronic</th>\n",
       "      <th>zolmitriptan</th>\n",
       "      <th>zometa</th>\n",
       "      <th>zone</th>\n",
       "      <th>zubrod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10752 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    01  01910na  025   05   09  0three_two9  0two_two009  10deazaaminopterin  \\\n",
       "0  0.0      0.0  0.0  0.0  0.0          0.0          0.0                 0.0   \n",
       "1  0.0      0.0  0.0  0.0  0.0          0.0          0.0                 0.0   \n",
       "2  0.0      0.0  0.0  0.0  0.0          0.0          0.0                 0.0   \n",
       "3  0.0      0.0  0.0  0.0  0.0          0.0          0.0                 0.0   \n",
       "4  0.0      0.0  0.0  0.0  0.0          0.0          0.0                 0.0   \n",
       "\n",
       "    11   12  ...  zivaflibercept   zk  zoladex  zoledron  zoledronate  \\\n",
       "0  0.0  0.0  ...             0.0  0.0      0.0       0.0          0.0   \n",
       "1  0.0  0.0  ...             0.0  0.0      0.0       0.0          0.0   \n",
       "2  0.0  0.0  ...             0.0  0.0      0.0       0.0          0.0   \n",
       "3  0.0  0.0  ...             0.0  0.0      0.0       0.0          0.0   \n",
       "4  0.0  0.0  ...             0.0  0.0      0.0       0.0          0.0   \n",
       "\n",
       "   zoledronic  zolmitriptan  zometa  zone  zubrod  \n",
       "0         0.0           0.0     0.0   0.0     0.0  \n",
       "1         0.0           0.0     0.0   0.0     0.0  \n",
       "2         0.0           0.0     0.0   0.0     0.0  \n",
       "3         0.0           0.0     0.0   0.0     0.0  \n",
       "4         0.0           0.0     0.0   0.0     0.0  \n",
       "\n",
       "[5 rows x 10752 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source: https://towardsdatascience.com/natural-language-processing-feature-engineering-using-tf-idf-e8b9d00e7e76\n",
    "vectorizer = TfidfVectorizer()\n",
    "allDocs = []\n",
    "for word in data_t['words']:\n",
    "    allDocs.append(word)\n",
    "vectors = vectorizer.fit_transform(allDocs)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "data_tfidf = pd.DataFrame(denselist, columns=feature_names)\n",
    "data_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RcDb3SXef5Z0"
   },
   "source": [
    "## Modelado con Support Vector Machies (Simón Guzmán L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se selecciona la variable objetivo, en este caso \"label\".\n",
    "Y = data_t['label']\n",
    "# Se pasan como inputs los valores a los que se les aplicó TF_IDF\n",
    "X = data_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']}\n",
    " \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.743 total time= 7.3min\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.752 total time= 7.6min\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.746 total time= 7.9min\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.751 total time= 7.8min\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.768 total time= 7.7min\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.674 total time= 8.3min\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.670 total time= 8.2min\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.672 total time= 7.8min\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.670 total time= 7.4min\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.677 total time= 7.7min\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.502 total time= 7.7min\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.502 total time= 7.8min\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.502 total time= 7.8min\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.503 total time= 7.6min\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.503 total time= 7.5min\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.502 total time= 7.6min\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.502 total time= 8.2min\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.502 total time= 8.1min\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.503 total time= 8.2min\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.503 total time= 8.0min\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.502 total time= 8.1min\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.502 total time= 8.2min\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.502 total time= 8.0min\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.503 total time= 9.0min\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.503 total time= 8.0min\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.803 total time= 6.3min\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.810 total time= 6.3min\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.824 total time= 6.3min\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.823 total time= 6.1min\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.817 total time= 5.9min\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.780 total time= 5.9min\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.794 total time= 5.9min\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.799 total time= 5.9min\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.791 total time= 5.9min\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.798 total time= 5.9min\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.686 total time= 7.7min\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.692 total time= 7.4min\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.689 total time= 7.5min\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.690 total time= 7.6min\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.704 total time=33.8min\n",
      "[CV 1/5] END .....C=1, gamma=0.001, kernel=rbf;, score=0.502 total time=184.8min\n",
      "[CV 2/5] END .....C=1, gamma=0.001, kernel=rbf;, score=0.502 total time=122.9min\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.502 total time= 7.3min\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.503 total time= 7.4min\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.503 total time= 7.3min\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.502 total time= 7.3min\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.502 total time= 7.3min\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.502 total time= 7.4min\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.503 total time= 7.3min\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.503 total time= 7.3min\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.809 total time= 6.9min\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.822 total time= 6.9min\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.827 total time= 6.9min\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.814 total time= 7.0min\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.821 total time= 7.0min\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.788 total time= 4.3min\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.804 total time= 4.4min\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.804 total time= 4.4min\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.802 total time= 4.4min\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.799 total time= 4.4min\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.777 total time= 5.5min\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.794 total time= 5.5min\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.797 total time= 5.5min\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.795 total time= 5.6min\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.796 total time= 5.5min\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.689 total time= 7.2min\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.694 total time= 7.2min\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.690 total time= 7.2min\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.692 total time= 7.3min\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.703 total time= 7.2min\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.502 total time= 7.3min\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.502 total time= 7.3min\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.502 total time= 7.3min\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.503 total time= 7.3min\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.503 total time= 7.3min\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.809 total time= 6.9min\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.822 total time= 6.9min\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.828 total time= 7.0min\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.815 total time= 7.1min\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.821 total time= 7.0min\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.776 total time= 5.1min\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.791 total time= 6.1min\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.790 total time= 6.1min\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.797 total time= 6.1min\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.793 total time= 5.2min\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.788 total time= 4.2min\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.797 total time= 4.2min\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.802 total time= 4.2min\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.799 total time= 4.2min\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.797 total time= 4.2min\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.777 total time= 5.4min\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.794 total time= 5.5min\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.796 total time= 5.4min\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.794 total time= 5.5min\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.795 total time= 5.5min\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.689 total time= 7.4min\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.694 total time= 7.1min\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.690 total time= 7.1min\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.692 total time= 7.1min\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.704 total time= 7.1min\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.809 total time= 6.9min\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.822 total time= 6.9min\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.828 total time= 7.0min\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.815 total time= 7.0min\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.821 total time= 7.0min\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.769 total time= 5.2min\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.780 total time= 6.2min\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.787 total time= 5.3min\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.794 total time= 6.2min\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.786 total time= 6.4min\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.770 total time= 4.1min\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.782 total time= 4.1min\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.779 total time= 4.1min\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.791 total time= 4.1min\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.782 total time= 4.1min\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.787 total time= 4.7min\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.796 total time= 4.7min\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.801 total time= 4.8min\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.797 total time= 5.0min\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.797 total time= 5.1min\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.777 total time= 6.1min\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.794 total time= 6.2min\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.796 total time= 6.3min\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.794 total time= 6.1min\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.795 total time= 5.8min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model for grid search\n",
    "grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 1, 'kernel': 'rbf'}\n",
      "SVC(C=100, gamma=1)\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    " \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1219\n",
      "           1       0.81      0.83      0.82      1179\n",
      "\n",
      "    accuracy                           0.82      2398\n",
      "   macro avg       0.82      0.82      0.82      2398\n",
      "weighted avg       0.82      0.82      0.82      2398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_predictions = grid.predict(X_test)\n",
    " \n",
    "# print classification report\n",
    "print(classification_report(Y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOOHGOaVca5hIRFsPy5p6Va",
   "collapsed_sections": [],
   "mount_file_id": "1CLBbpZr8zhWKkmCYQXQBSbzBdCk5xPVb",
   "name": "Proyecto1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
